#!/usr/bin/env python3
"""
NewAPI ä¿¡æ¯æå–å·¥å…·ï¼ˆå‘½ä»¤è¡Œç‰ˆï¼‰

ä½¿ç”¨ Patchright/Playwright æ‰“å¼€æµè§ˆå™¨ï¼Œè‡ªåŠ¨ä»Ž NewAPI ç«™ç‚¹æå–ï¼š
- ç”¨æˆ·å (username)
- API User ID
- API Key (token)

è¿è¡Œæ–¹å¼: uv run python scripts/newapi_extractor_browser.py
"""

import asyncio
import contextlib
import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, str(Path(__file__).parent.parent))

# å°è¯•å¯¼å…¥æµè§ˆå™¨åº“
try:
    from patchright.async_api import async_playwright
    BROWSER_LIB = "patchright"
except ImportError:
    try:
        from playwright.async_api import async_playwright
        BROWSER_LIB = "playwright"
    except ImportError:
        print("âŒ è¯·å…ˆå®‰è£… patchright æˆ– playwright:")
        print("   uv add patchright")
        sys.exit(1)


# NewAPI ç«™ç‚¹é…ç½®
NEWAPI_SITES = {
    "wong": {
        "name": "WONGå…¬ç›Šç«™",
        "url": "https://wzw.pp.ua",
        "linuxdo_user": "jason_wong1",
    },
    "elysiver": {
        "name": "Elysiver",
        "url": "https://elysiver.h-e.top",
        "linuxdo_user": "bytebender",
    },
    "kfcapi": {
        "name": "KFC API",
        "url": "https://kfc-api.sxxe.net",
        "linuxdo_user": "kkkyyx",
    },
    "duckcoding": {
        "name": "Free DuckCoding",
        "url": "https://free.duckcoding.com",
        "linuxdo_user": "wcyrus",
    },
    "runanytime": {
        "name": "éšæ—¶è·‘è·¯",
        "url": "https://runanytime.hxi.me",
        "linuxdo_user": "henryxiaoyang",
    },
    "neb": {
        "name": "NEBå…¬ç›Šç«™",
        "url": "https://ai.zzhdsgsss.xyz",
        "linuxdo_user": "simon_z",
    },
    "zeroliya": {
        "name": "å°å‘†å…¬ç›Šç«™",
        "url": "https://new.184772.xyz",
        "linuxdo_user": "zeroliya",
    },
    "mitchll": {
        "name": "Mitchll-api",
        "url": "https://api.mitchll.com",
        "linuxdo_user": "mitchll",
    },
    "anyrouter": {
        "name": "AnyRouter",
        "url": "https://anyrouter.top",
        "linuxdo_user": "technologystar",
    },
    "zhongruan": {
        "name": "é’Ÿé˜®å…¬ç›Šç«™",
        "url": "https://gyapi.zxiaoruan.cn",
        "linuxdo_user": "zhongruan",
    },
    "apikey": {
        "name": "apikeyå…¬ç›Šç«™",
        "url": "https://welfare.apikey.cc",
        "linuxdo_user": "freenessfish",
    },
    "lightllm": {
        "name": "è½»ã®LLM",
        "url": "https://lightllm.online",
        "linuxdo_user": "foward",
    },
    "windhub": {
        "name": "Wind Hubå…¬ç›Šç«™",
        "url": "https://api.224442.xyz",
        "linuxdo_user": "beizhi",
    },
    "hotaru": {
        "name": "Hotaru API",
        "url": "https://api.hotaruapi.top",
        "linuxdo_user": "mazhichen8780",
    },
    "dev88": {
        "name": "DEV88å…¬ç›Šç«™",
        "url": "https://api.dev88.tech",
        "linuxdo_user": "sc0152",
    },
}

BROWSER_DATA_DIR = Path("browser_data/newapi_extractor")


async def extract_from_site(page, site_id: str, config: dict) -> dict | None:
    """ä»Žå•ä¸ªç«™ç‚¹æå–ä¿¡æ¯"""
    url = f"{config['url']}/console/personal"
    print(f"\nðŸ“ æ­£åœ¨è®¿é—®: {config['name']} ({url})")

    try:
        await page.goto(url, timeout=30000)
        await page.wait_for_load_state("networkidle", timeout=10000)
        await asyncio.sleep(1)

        # ä»Ž localStorage èŽ·å–ç”¨æˆ·ä¿¡æ¯
        user_info = await page.evaluate("""
            () => {
                try {
                    const userStr = localStorage.getItem('user');
                    const user = userStr ? JSON.parse(userStr) : {};
                    const token = localStorage.getItem('token') || '';
                    return {
                        username: user.username || user.display_name || '',
                        api_user: user.id ? String(user.id) : '',
                        api_key: token,
                        email: user.email || '',
                        success: true
                    };
                } catch (e) {
                    return { success: false, error: e.message };
                }
            }
        """)

        if user_info and user_info.get('success') and user_info.get('username'):
            print(f"  âœ… ç”¨æˆ·å: {user_info['username']}")
            print(f"  âœ… API User: {user_info['api_user']}")
            api_key_display = user_info['api_key'][:30] + "..." if user_info.get('api_key') else "æœªæ‰¾åˆ°"
            print(f"  âœ… API Key: {api_key_display}")
            return {
                "site_id": site_id,
                "name": config["name"],
                "url": config["url"],
                "linuxdo_user": config["linuxdo_user"],
                **user_info
            }
        else:
            print("  âŒ æœªç™»å½•æˆ–æ— æ³•èŽ·å–ä¿¡æ¯")
            return None

    except Exception as e:
        print(f"  âŒ è®¿é—®å¤±è´¥: {e}")
        return None


async def login_mode(selected_sites: list):
    """ç™»å½•æ¨¡å¼ï¼šæ‰“å¼€æµè§ˆå™¨è®©ç”¨æˆ·ç™»å½•"""
    print("\nðŸŒ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
    print("è¯·åœ¨æµè§ˆå™¨ä¸­ç™»å½•å„ç«™ç‚¹ï¼Œå®ŒæˆåŽå…³é—­æµè§ˆå™¨çª—å£ã€‚\n")

    BROWSER_DATA_DIR.mkdir(parents=True, exist_ok=True)

    async with async_playwright() as p:
        context = await p.chromium.launch_persistent_context(
            user_data_dir=str(BROWSER_DATA_DIR),
            headless=False,
            args=["--disable-blink-features=AutomationControlled"],
        )

        page = context.pages[0] if context.pages else await context.new_page()

        # æ‰“å¼€ç¬¬ä¸€ä¸ªç«™ç‚¹çš„ç™»å½•é¡µ
        if selected_sites:
            first_site = NEWAPI_SITES[selected_sites[0]]
            await page.goto(f"{first_site['url']}/login")

        print("ðŸ’¡ æç¤ºï¼šç™»å½•å®ŒæˆåŽï¼Œå…³é—­æµè§ˆå™¨çª—å£å³å¯ã€‚")

        # ç­‰å¾…ç”¨æˆ·å…³é—­æµè§ˆå™¨
        with contextlib.suppress(Exception):
            await page.wait_for_event("close", timeout=600000)

        await context.close()

    print("\nâœ… æµè§ˆå™¨å·²å…³é—­ã€‚")


async def extract_mode(selected_sites: list) -> list:
    """æå–æ¨¡å¼ï¼šä»Žå·²ç™»å½•çš„ç«™ç‚¹æå–ä¿¡æ¯"""
    results = []

    if not BROWSER_DATA_DIR.exists():
        print("âŒ æµè§ˆå™¨æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œç™»å½•æ¨¡å¼ã€‚")
        return results

    print(f"\nðŸ” ä½¿ç”¨ {BROWSER_LIB} æå–ä¿¡æ¯...")

    async with async_playwright() as p:
        context = await p.chromium.launch_persistent_context(
            user_data_dir=str(BROWSER_DATA_DIR),
            headless=True,
            args=["--disable-blink-features=AutomationControlled"],
        )

        page = context.pages[0] if context.pages else await context.new_page()

        for site_id in selected_sites:
            config = NEWAPI_SITES[site_id]
            result = await extract_from_site(page, site_id, config)
            if result:
                results.append(result)

        await context.close()

    return results


def print_results(results: list):
    """æ‰“å°ç»“æžœ"""
    print("\n" + "=" * 60)
    print("ðŸ“Š æå–ç»“æžœ")
    print("=" * 60)

    if results:
        # ç”Ÿæˆ Markdown è¡¨æ ¼
        for item in results:
            print(f"\n### {item['name']}\n")
            print("| é¡¹ç›® | å€¼ |")
            print("| -------- | --------------------------------------------------- |")
            print(f"| ç”¨æˆ·å | {item['username']} |")
            print(f"| API User | {item['api_user']} |")
            print(f"| API Key | {item['api_key']} |")

        # ä¿å­˜åˆ°æ–‡ä»¶
        output_file = "newapi_extracted.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nâœ… ç»“æžœå·²ä¿å­˜åˆ° {output_file}")

        # ç”Ÿæˆæ±‡æ€»æ ¼å¼
        print("\n## ä¸­è½¬ç«™æ±‡æ€»æ ¼å¼\n")
        for item in results:
            linuxdo_url = f"https://linux.do/u/{item['linuxdo_user']}/summary"
            print(f"{linuxdo_url}\t{item['name']}\t{item['url']}")
    else:
        print("\nâŒ æœªæå–åˆ°ä»»ä½•ä¿¡æ¯")
        print("è¯·å…ˆè¿è¡Œç™»å½•æ¨¡å¼ï¼Œåœ¨æµè§ˆå™¨ä¸­ç™»å½•å„ç«™ç‚¹ã€‚")


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ðŸ”‘ NewAPI ä¿¡æ¯æå–å·¥å…·")
    print("=" * 60)

    # æ˜¾ç¤ºå¯ç”¨ç«™ç‚¹
    print("\nå¯ç”¨ç«™ç‚¹:")
    site_keys = list(NEWAPI_SITES.keys())
    for i, site_id in enumerate(site_keys, 1):
        config = NEWAPI_SITES[site_id]
        print(f"  {i:2}. {config['name']} ({config['url']})")

    # é€‰æ‹©ç«™ç‚¹
    print("\nè¾“å…¥è¦æ“ä½œçš„ç«™ç‚¹ç¼–å·ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ï¼Œæˆ–è¾“å…¥ 'all' é€‰æ‹©å…¨éƒ¨:")
    choice = input("> ").strip()

    if choice.lower() == 'all':
        selected_sites = site_keys
    else:
        try:
            indices = [int(x.strip()) - 1 for x in choice.split(",")]
            selected_sites = [site_keys[i] for i in indices if 0 <= i < len(site_keys)]
        except ValueError:
            print("âŒ è¾“å…¥æ— æ•ˆ")
            return

    if not selected_sites:
        print("âŒ æœªé€‰æ‹©ä»»ä½•ç«™ç‚¹")
        return

    print(f"\nå·²é€‰æ‹©: {', '.join(selected_sites)}")

    # é€‰æ‹©æ¨¡å¼
    print("\né€‰æ‹©æ“ä½œæ¨¡å¼:")
    print("  1. ç™»å½•æ¨¡å¼ - æ‰“å¼€æµè§ˆå™¨ç™»å½•å„ç«™ç‚¹")
    print("  2. æå–æ¨¡å¼ - ä»Žå·²ç™»å½•çš„ç«™ç‚¹æå–ä¿¡æ¯")
    print("  3. å®Œæ•´æµç¨‹ - å…ˆç™»å½•å†æå–")

    mode = input("\nè¯·é€‰æ‹© (1/2/3): ").strip()

    if mode == "1":
        await login_mode(selected_sites)
    elif mode == "2":
        results = await extract_mode(selected_sites)
        print_results(results)
    elif mode == "3":
        await login_mode(selected_sites)
        print("\nå‡†å¤‡æå–ä¿¡æ¯...")
        results = await extract_mode(selected_sites)
        print_results(results)
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")


if __name__ == "__main__":
    asyncio.run(main())
